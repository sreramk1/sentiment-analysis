{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment analysis experiment 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1xOmv0_i6gUvCQb6yLDMe1jjbTwFxCqkG",
      "authorship_tag": "ABX9TyPKCSkprXAQwSrQ8LbVw+56"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HR5ytb_Ry0K"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tf.config.run_functions_eagerly(False) \n",
        "#tfds.disable_progress_bar()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0KQT2tePDkDw",
        "outputId": "638f214a-f945-46df-faee-3a7ed9e6447b"
      },
      "source": [
        "tf.version.VERSION"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4auN5BspoIj"
      },
      "source": [
        "import pandas as pd "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tg1c8ebnpsQ2"
      },
      "source": [
        "dataset = pd.read_csv(\"/content/drive/MyDrive/sentiment-dataset/airline_sentiment_analysis.csv\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bWXiQf3hB14",
        "outputId": "617c391a-c817-4fca-ab50-3ca29fb1e8e9"
      },
      "source": [
        "print (dataset[:10])\n",
        "print (dataset[len(dataset) - 10:])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  ...                                               text\n",
            "0           1  ...  @VirginAmerica plus you've added commercials t...\n",
            "1           3  ...  @VirginAmerica it's really aggressive to blast...\n",
            "2           4  ...  @VirginAmerica and it's a really big bad thing...\n",
            "3           5  ...  @VirginAmerica seriously would pay $30 a fligh...\n",
            "4           6  ...  @VirginAmerica yes, nearly every time I fly VX...\n",
            "5           8  ...    @virginamerica Well, I didn'tâ€¦but NOW I DO! :-D\n",
            "6           9  ...  @VirginAmerica it was amazing, and arrived an ...\n",
            "7          11  ...  @VirginAmerica I &lt;3 pretty graphics. so muc...\n",
            "8          12  ...  @VirginAmerica This is such a great deal! Alre...\n",
            "9          13  ...  @VirginAmerica @virginmedia I'm flying your #f...\n",
            "\n",
            "[10 rows x 3 columns]\n",
            "       Unnamed: 0  ...                                               text\n",
            "11531       14627  ...  @AmericanAir Flight Cancelled Flightled, can't...\n",
            "11532       14628  ...  Thank you. â€œ@AmericanAir: @jlhalldc Customer R...\n",
            "11533       14629  ...  @AmericanAir How do I change my flight if the ...\n",
            "11534       14630  ...                        @AmericanAir Thanks! He is.\n",
            "11535       14631  ...  @AmericanAir thx for nothing on getting us out...\n",
            "11536       14633  ...  @AmericanAir my flight was Cancelled Flightled...\n",
            "11537       14634  ...         @AmericanAir right on cue with the delaysðŸ‘Œ\n",
            "11538       14635  ...  @AmericanAir thank you we got on a different f...\n",
            "11539       14636  ...  @AmericanAir leaving over 20 minutes Late Flig...\n",
            "11540       14638  ...  @AmericanAir you have my money, you change my ...\n",
            "\n",
            "[10 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lk77OjUlieCU",
        "outputId": "68963d19-110c-48c8-e3c8-a0cf41630a31"
      },
      "source": [
        "def process(txt):\n",
        "  return ' '.join(word for word in txt.split(' ') if not word.startswith('@'))\n",
        "\n",
        "process(\" word1 word2     word3 @word4 word5   word6\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' word1 word2     word3 word5   word6'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFyI-RfMhio7",
        "outputId": "c6993af2-bec8-4454-d8a0-df369e75f4ae"
      },
      "source": [
        "dataset_processed = pd.DataFrame.copy(dataset, deep=True)\n",
        "\n",
        "dataset_processed['text'] = dataset['text'].apply(process)\n",
        "print(dataset_processed[:3])\n",
        "print(dataset_processed[len(dataset_processed) - 3:])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0  ...                                               text\n",
            "0           1  ...  plus you've added commercials to the experienc...\n",
            "1           3  ...  it's really aggressive to blast obnoxious \"ent...\n",
            "2           4  ...           and it's a really big bad thing about it\n",
            "\n",
            "[3 rows x 3 columns]\n",
            "       Unnamed: 0  ...                                               text\n",
            "11538       14635  ...  thank you we got on a different flight to Chic...\n",
            "11539       14636  ...  leaving over 20 minutes Late Flight. No warnin...\n",
            "11540       14638  ...  you have my money, you change my flight, and d...\n",
            "\n",
            "[3 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBdMOFURjyAI"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyF_2cmUYWAN"
      },
      "source": [
        "def process_label(label):\n",
        "  if label == \"negative\":\n",
        "    return 0\n",
        "  elif label == \"positive\":\n",
        "    return 1\n",
        "  raise Exception(\"unrecognized label\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36rBD47XYIwk"
      },
      "source": [
        "dataset_processed['airline_sentiment'] = dataset_processed['airline_sentiment'].apply(process_label)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8n3htv4mkedD"
      },
      "source": [
        "dataset_train, dataset_test = train_test_split(dataset_processed, test_size = 0.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 834
        },
        "id": "YSflq7lbPJXg",
        "outputId": "ca940321-7085-4d9c-e82b-6796b95e3ccf"
      },
      "source": [
        "dataset_train[100:125]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8867</th>\n",
              "      <td>11457</td>\n",
              "      <td>0</td>\n",
              "      <td>Spoke on the phone 3 or 4 times, but no resolu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2986</th>\n",
              "      <td>3741</td>\n",
              "      <td>1</td>\n",
              "      <td>can I just go ahead and live in your premium c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4861</th>\n",
              "      <td>6280</td>\n",
              "      <td>1</td>\n",
              "      <td>oh my god LAUREN OH MY GOD OH MY GOD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>605</td>\n",
              "      <td>0</td>\n",
              "      <td>I tried but no one was available in bogota and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3001</th>\n",
              "      <td>3757</td>\n",
              "      <td>0</td>\n",
              "      <td>still can't dm, it's LH7631 on 21/2/15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7418</th>\n",
              "      <td>9800</td>\n",
              "      <td>0</td>\n",
              "      <td>Any word on accommodations for the passengers ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1853</th>\n",
              "      <td>2333</td>\n",
              "      <td>0</td>\n",
              "      <td>no, your service here pretty much ruined my da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11026</th>\n",
              "      <td>14053</td>\n",
              "      <td>0</td>\n",
              "      <td>already did &amp;amp; an automated voice told us t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1478</th>\n",
              "      <td>1878</td>\n",
              "      <td>0</td>\n",
              "      <td>who authors this fiction? I just heard on radi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>946</th>\n",
              "      <td>1252</td>\n",
              "      <td>0</td>\n",
              "      <td>We were supposed to board at 605. They just br...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7273</th>\n",
              "      <td>9642</td>\n",
              "      <td>0</td>\n",
              "      <td>how do I get off my plane and wait over an hou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5171</th>\n",
              "      <td>6691</td>\n",
              "      <td>0</td>\n",
              "      <td>I've been on hold for an hour &amp;amp; a half try...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>1558</td>\n",
              "      <td>0</td>\n",
              "      <td>this is it... Last time I fly #UnitedAirlines ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10987</th>\n",
              "      <td>14004</td>\n",
              "      <td>0</td>\n",
              "      <td>that's the number I called -it wouldn't let me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7339</th>\n",
              "      <td>9712</td>\n",
              "      <td>0</td>\n",
              "      <td>comedy of errors continues...\" We can't get in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5127</th>\n",
              "      <td>6629</td>\n",
              "      <td>0</td>\n",
              "      <td>how about when there are Cancelled Flightlatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6467</th>\n",
              "      <td>8618</td>\n",
              "      <td>0</td>\n",
              "      <td>but you guys should know that musicians are ve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8024</th>\n",
              "      <td>10473</td>\n",
              "      <td>0</td>\n",
              "      <td>status shows \"delayed\" it was just \"waiting fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3632</th>\n",
              "      <td>4563</td>\n",
              "      <td>0</td>\n",
              "      <td>you Cancelled Flightled my flight and now I am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7953</th>\n",
              "      <td>10390</td>\n",
              "      <td>1</td>\n",
              "      <td>Thanks guys! Got hold of someone. Really aweso...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3164</th>\n",
              "      <td>3960</td>\n",
              "      <td>0</td>\n",
              "      <td>still haven't received a response. Please dire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7977</th>\n",
              "      <td>10418</td>\n",
              "      <td>0</td>\n",
              "      <td>how about an update with real information?stil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1389</th>\n",
              "      <td>1768</td>\n",
              "      <td>0</td>\n",
              "      <td>says we had a weather delay in #YXE this morni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4167</th>\n",
              "      <td>5274</td>\n",
              "      <td>0</td>\n",
              "      <td>placed on hold for total of two hours today a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5012</th>\n",
              "      <td>6478</td>\n",
              "      <td>1</td>\n",
              "      <td>really appreciate the follow up, I always fly ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0  ...                                               text\n",
              "8867        11457  ...  Spoke on the phone 3 or 4 times, but no resolu...\n",
              "2986         3741  ...  can I just go ahead and live in your premium c...\n",
              "4861         6280  ...               oh my god LAUREN OH MY GOD OH MY GOD\n",
              "409           605  ...  I tried but no one was available in bogota and...\n",
              "3001         3757  ...             still can't dm, it's LH7631 on 21/2/15\n",
              "7418         9800  ...  Any word on accommodations for the passengers ...\n",
              "1853         2333  ...  no, your service here pretty much ruined my da...\n",
              "11026       14053  ...  already did &amp; an automated voice told us t...\n",
              "1478         1878  ...  who authors this fiction? I just heard on radi...\n",
              "946          1252  ...  We were supposed to board at 605. They just br...\n",
              "7273         9642  ...  how do I get off my plane and wait over an hou...\n",
              "5171         6691  ...  I've been on hold for an hour &amp; a half try...\n",
              "1206         1558  ...  this is it... Last time I fly #UnitedAirlines ...\n",
              "10987       14004  ...  that's the number I called -it wouldn't let me...\n",
              "7339         9712  ...  comedy of errors continues...\" We can't get in...\n",
              "5127         6629  ...  how about when there are Cancelled Flightlatio...\n",
              "6467         8618  ...  but you guys should know that musicians are ve...\n",
              "8024        10473  ...  status shows \"delayed\" it was just \"waiting fo...\n",
              "3632         4563  ...  you Cancelled Flightled my flight and now I am...\n",
              "7953        10390  ...  Thanks guys! Got hold of someone. Really aweso...\n",
              "3164         3960  ...  still haven't received a response. Please dire...\n",
              "7977        10418  ...  how about an update with real information?stil...\n",
              "1389         1768  ...  says we had a weather delay in #YXE this morni...\n",
              "4167         5274  ...   placed on hold for total of two hours today a...\n",
              "5012         6478  ...  really appreciate the follow up, I always fly ...\n",
              "\n",
              "[25 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvxCZJS-FJCx",
        "outputId": "cd15aab9-37b2-4a21-e3cd-d53a0f8cc24a"
      },
      "source": [
        "len(dataset_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9232"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wMtz6h7oR0P"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eUCA-WlTaTo"
      },
      "source": [
        "dataset_train_text_tf = tf.convert_to_tensor(dataset_train['text'], dtype=tf.string)\n",
        "dataset_train_label_tf = tf.convert_to_tensor(dataset_train['airline_sentiment'], dtype=tf.float32)\n",
        "\n",
        "dataset_test_text_tf = tf.convert_to_tensor(dataset_test['text'], dtype=tf.string)\n",
        "dataset_test_lable_tf = tf.convert_to_tensor(dataset_test['airline_sentiment'], dtype=tf.float32)\n",
        "\n",
        "dataset_train_tf = tf.data.Dataset.from_tensor_slices((dataset_train_text_tf, dataset_train_label_tf))\n",
        "dataset_test_tf = tf.data.Dataset.from_tensor_slices((dataset_test_text_tf, dataset_test_lable_tf))\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzM_q-DRXcAz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc08d3e-318f-4605-d701-aebed37e9990"
      },
      "source": [
        "count = 10\n",
        "i = 0\n",
        "for ele in dataset_train_tf.as_numpy_iterator():\n",
        "  if i >= count: \n",
        "    break\n",
        "  print (ele)\n",
        "  i += 1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(b'why must you always delay my Late Flight night Orlando flights? \\xf0\\x9f\\x92\\x94', 0.0)\n",
            "(b'So appreciated!', 1.0)\n",
            "(b'thanks, keep up the good work', 1.0)\n",
            "(b\"we never received that $15 credit for inoperable tv's on our SFO &gt; JFK flight 2 weeks ago. never got an email...\", 0.0)\n",
            "(b'what response? Is our flight out of Montrose Cancelled Flightled or not?', 0.0)\n",
            "(b\"so you don't have a pilot now for #clt \\xe2\\x9c\\x88 #ord for at least another hour. Why on earth would you board the plane? Makes no sense!\", 0.0)\n",
            "(b\"LUV Ya Too!!!!  I will sing a song for y'all when I finally get on that plane back to Nashville!!! #LOVESOUTHWESTAIR\", 1.0)\n",
            "(b\"she's the type of person that can make a customers day! I fly 100+ times a year &amp; she's one of the top flight attendants I've had!\", 1.0)\n",
            "(b\"really not acceptable. Just informed plane won't start. Chartering bus to take passengers to jfk.\", 0.0)\n",
            "(b'Also, been on hold for 30 minutes with your \"customer service\" to find out when my new flight is scheduled bc your site SUCKS', 0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Zwy01LUFad"
      },
      "source": [
        "train_dataset_batched_tf = dataset_train_tf.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset_batched_tf = dataset_test_tf.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJBNlEdcWCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cabe34e9-26d2-46ec-e9c5-a8e6e012f43f"
      },
      "source": [
        "count = 1\n",
        "i = 0\n",
        "for ele in train_dataset_batched_tf.as_numpy_iterator():\n",
        "  if i >= count: \n",
        "    break\n",
        "  print (ele)\n",
        "  i += 1"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([b\"Fine. Would you have them call me? I left a message, was told it would be 2 hours for a call. Haven't heard anything yet.\",\n",
            "       b\"thanks! Y'all have some of the best customer service left in the industry.\",\n",
            "       b\"it's been 2 hrs of wait on the phone a) worst customer services b) trying to know where my suitcase Is and way MORE \\xf0\\x9f\\x98\\xa4#ANGRY\",\n",
            "       b\"I cheated on you, and I'm sorry. I'll never do it again. has given my wife and I the worst start to a honeymoon ever\",\n",
            "       b'a $100 - totaled. Not happy. Not at all.',\n",
            "       b'is gettin fancy! #Mint #LieFlat Nice work on the menu #LobsterMac #BloodyMary #JetSetter http://t.co/zf5wjgtXzT',\n",
            "       b\"when trying to check-in online, it says to call...now I've been on hold for 2 hours...what to do?\",\n",
            "       b'.@USAirways trying to get a partner PNR, and have spent more than 1 hour on hold.  I know its snowing somewhere, but this is awful',\n",
            "       b'not an issue but I think training &amp; information would help. Great ppl but service needs to switch from individual to group better',\n",
            "       b'worst experience with you. Cancelled Flightled flight, no voucher and no luggage because \"ramp was broken.\" No other ramps in Charlotte??',\n",
            "       b\"I fly normally.  This doesn't happen to me with them.  I'll let your flyers provide their own feedback. Thank you.\",\n",
            "       b'I guess the Kit Kat looks tasty... not going near that \"sandwich.\"',\n",
            "       b\"Thank y'all for being an amazing airline who knows how to treat their customers. you guys rock!\",\n",
            "       b\"yet again you disappoint. Sitting at IAD for UA3728 for 3.5hrs and you can't seem to know why the plane hasn't left Albany. #Fail\",\n",
            "       b'once again flying AA4285, once again 60+ min delay because of mechanical issues. Perhaps you should consider maintenance?',\n",
            "       b'great. Looking forward to your response to my DM then',\n",
            "       b'...be found when he checks in. Now no info. Please DM me and help me fix this NOW. (3/3)',\n",
            "       b\"Hey, first time flyer next week - excited! But I'm having a hard time getting my flights added to my Elevate account. Help?\",\n",
            "       b'gate agents are now working with everyone to resolve connecting flight issues which is my concern',\n",
            "       b'Rebooked for tomorrow morning. Never been here - not sure what I can see before tomorrow morning!',\n",
            "       b'this is not a fair set up. I payed for a full seat. I should get access to a full seat. http://t.co/SbA0ARicyq',\n",
            "       b\"customers aren't dumb. These revenue based programs will hurt everyone. Not gonna save money like you think\",\n",
            "       b'thank you for always have the most amazing customer service! Bring on The Disney Princess Half Marathon',\n",
            "       b'I did see that! Working on picking up a trip or two as we type.',\n",
            "       b'no my concerns were not addressed',\n",
            "       b'please help! No bags, no way to get through to customer service since 8AM this morning! Help!!',\n",
            "       b'  Yes. Dale at Baggage office was wonderful. But not everyone is on the same page down there... We had a 6 hour wait!',\n",
            "       b'appreciate it!!',\n",
            "       b\"Issue is JFK. Pilot explained once JFK reopens we can get scheduled back there, but why can't we divert to LGA? Closer than ACY!\",\n",
            "       b\"by far the worst airline in history. I'll never ever fly your garbage again\",\n",
            "       b\"ok it's now been 7 months waiting to hear from airline. I gave them quite a bit more than the 30 days requested! Terrible service\",\n",
            "       b\"passengers seated, crew ready #WheresThePilot? Flt1088 from ORD. Hope he isn't at the bar.\",\n",
            "       b'worst airline ever! Staff is nasty, wifi down bags are delayed due to weather?? And now the belt is broken. Selling UAL stock in AM',\n",
            "       b\"that's what you have said for years, you are losing customers!!!!!!\",\n",
            "       b\"nope I gave up - maybe they'll deliver it\",\n",
            "       b'And now the flight Flight Booking Problems site is totally down. Folks, what is the problem?',\n",
            "       b\"only thing confusing me is why I lost priority boarding? I'm a mileage plus card member \\xf0\\x9f\\x98\\x94\",\n",
            "       b'all right, but can you give me an email to write to ?',\n",
            "       b'thanks for the show! \\xf0\\x9f\\x91\\x8d',\n",
            "       b'it took ages for one snapchat story to load. one. ONE. I will demolish you',\n",
            "       b\"we're home, you guys recovered, now we can laugh about it and the extra day in barbados. Will you open Cuba soon?\",\n",
            "       b'negative. Done wasting time with amateurs at customer service. Thanks for at least offering.',\n",
            "       b'- thanks. She submitted a damaged bag complaint online...is there anything else we can do? #goodcustomerservice',\n",
            "       b'The delay is nothing but the personnel being so combative up to the point of saying \"what\\'s the hury,  the plane is not leaving',\n",
            "       b'Thanks, she did her best. Staying the night in Dallas, new trial to Detroit via Atlanta tomorrow, assuming no Cancelled Flightlations.',\n",
            "       b'how can I get travel question answered quickly... Online and calling not helping with this busy day',\n",
            "       b'Not even on the bag status...will take actions against this company is incredible how irresponsible are with the costumer',\n",
            "       b'now maintenance issues with flight 5639 and more issues with passengers that will miss connections needing to get off',\n",
            "       b'Aww Thanks AA..DFW was on GMA up here this AM..so i understand ..Btw A.A is my Airline when im able to trv..Love you guys.:)',\n",
            "       b'is non existent and I will take this as far as needed.Why hide behind a corporate logo? Provide a number #tcf #useless #amateur',\n",
            "       b\"Thanks for the reminder of a few older flights I'd taken and the easy access to add points to my new JB account! Awesome service.\",\n",
            "       b'I Cancelled Flighted my flight. I really don\\xe2\\x80\\x99t need this much trouble.',\n",
            "       b\"it wasn't a delay so much as a straight Cancelled Flightlation. Weather wasn't an issue either.\",\n",
            "       b\"flt. 4567 departure time has changed five times in the last 20 minutes. Why don't you figure out a solution and announce once?\",\n",
            "       b'I am signed up for notifications. This is the first trip I was not updated on. Not sure why this happened.',\n",
            "       b\"Hi there, looks like my connection is delayed too so I'll make it. Thanks!\",\n",
            "       b\"How best to talk with an agent to reschedule Cancelled Flighted flight? No one answers at AA. Know it's busy, but need help.Thanks\",\n",
            "       b\"Thanks, both airlines said that it is located at AA Detroit. Also was informed that it flew with AA, which shouldn't matter.\",\n",
            "       b'I have a flight from omaha to chicago (en route to NYC) and they are seating me and my partner separate, please fix this res# ILC0HP',\n",
            "       b\"We're having 2 grandbabies in 2 weeks -- will travel to DC for the births. Thank you for the reasonable fares!  See you Saturday!\",\n",
            "       b'what maintenance?  The flight landed from Jamaica, has to go through security then get to term 3 then cleaned then board',\n",
            "       b'Hidden City forces me into crappy seat even though exit row is available on the first leg. Your support cannot fix. :-(',\n",
            "       b'#BQONPA flight #1641 delayed from POS-MIA, missed #2214 MIA- ATL need seat on last flight to ATL.',\n",
            "       b\"customer service failure aside, one would think you guys would care about inaccurate manifests. I'm sure TSA would.\"],\n",
            "      dtype=object), array([0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
            "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
            "       0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRy1T80MT_yu",
        "outputId": "94cf11a6-e725-4cf6-8da3-9e4965717d88"
      },
      "source": [
        "print(dataset_train_tf)\n",
        "print(dataset_test_tf)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.float32)>\n",
            "<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.float32)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaITHfsffR7r"
      },
      "source": [
        "#VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization()\n",
        "    #max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset_batched_tf.map(lambda text, label: text))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7ZWYSjNER7R"
      },
      "source": [
        "count_0 = len(train_dataset_batched_tf)\n",
        "count = 0\n",
        "for ds in train_dataset_batched_tf:\n",
        "  count += len(ds[0])\n",
        "  print(len(ds[0]))\n",
        "count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECuXPMqomEU-",
        "outputId": "37ddc2d5-6cd6-4c91-8f13-1a28876ddd59"
      },
      "source": [
        "encoder(\"hello world HELLO WORLD\")[:].numpy()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([977, 754, 977, 754])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE7UIy4Yhl_R"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9qnyxQBhq9W",
        "outputId": "23a47371-44c0-4ec2-edcc-de3edc075413"
      },
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[100:150]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['were', 'because', 'great', 'wait', '3', 'u', 'trying', 'ive',\n",
              "       'day', 'then', 'never', 'fly', 'did', 'only', 'airport', 'delay',\n",
              "       'really', 'even', 'any', 'minutes', 'home', 'going', '4', 'united',\n",
              "       'last', 'people', 'agent', 'weather', 'very', 'make', 'bags',\n",
              "       'should', 'off', 'know', 'another', 'luggage', 'told', 'good',\n",
              "       'worst', 'way', 'take', 'flying', 'lost', 'go', 'them', 'ever',\n",
              "       'here', 'hrs', 'crew', 'than'], dtype='<U46')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq4Katarh7Wx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b30a1315-ba09-49d5-b9fc-6c42367d6b59"
      },
      "source": [
        "for example, label in dataset_train_tf.take(1):\n",
        "  print('texts: ', example.numpy())\n",
        "  print()\n",
        "  print('labels: ', label.numpy())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  b'why must you always delay my Late Flight night Orlando flights? \\xf0\\x9f\\x92\\x94'\n",
            "\n",
            "labels:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb75fmMzlt3C"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "      encoder,\n",
        "      tf.keras.layers.Embedding(\n",
        "          input_dim=len(encoder.get_vocabulary()),\n",
        "          output_dim=64,\n",
        "          # Use masking to handle the variable sequence lengths\n",
        "          mask_zero=True),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "      tf.keras.layers.Dense(16, activation='relu'),\n",
        "      tf.keras.layers.Dense(8, activation='relu'),\n",
        "      tf.keras.layers.Dense(1) #, activation='sigmoid')\n",
        "  ])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILbfmonEnOBw",
        "outputId": "7c02fd73-fb27-42e7-8240-cc21f775f309"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "text_vectorization (TextVect (None, None)              0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 64)          770176    \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 128)               66048     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 16)                528       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 136       \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 847,233\n",
            "Trainable params: 847,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljvLWirJnPjY",
        "outputId": "db5ba9fd-9826-40c1-9bfe-3b1ad753b8cd"
      },
      "source": [
        "encoder(\"hello world. This is great\").numpy()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([977, 754,  25,  12, 102])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYij17V_nPg2"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy']) #run_eagerly=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYqVF42_nPmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "529d3fd2-5d51-4e7e-fa33-a71fdee3390d"
      },
      "source": [
        "history = model.fit(train_dataset_batched_tf, epochs=10,\n",
        "                    validation_data=test_dataset_batched_tf,\n",
        "                    validation_steps=30)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "145/145 [==============================] - 20s 87ms/step - loss: 0.6000 - accuracy: 0.7973 - val_loss: 0.4479 - val_accuracy: 0.7917\n",
            "Epoch 2/10\n",
            "145/145 [==============================] - 10s 71ms/step - loss: 0.4006 - accuracy: 0.7973 - val_loss: 0.3862 - val_accuracy: 0.7917\n",
            "Epoch 3/10\n",
            "145/145 [==============================] - 10s 71ms/step - loss: 0.3055 - accuracy: 0.7973 - val_loss: 0.3105 - val_accuracy: 0.7917\n",
            "Epoch 4/10\n",
            "145/145 [==============================] - 10s 72ms/step - loss: 0.2383 - accuracy: 0.7973 - val_loss: 0.2937 - val_accuracy: 0.7917\n",
            "Epoch 5/10\n",
            "145/145 [==============================] - 10s 72ms/step - loss: 0.1840 - accuracy: 0.8438 - val_loss: 0.2728 - val_accuracy: 0.8823\n",
            "Epoch 6/10\n",
            "145/145 [==============================] - 10s 71ms/step - loss: 0.1276 - accuracy: 0.9469 - val_loss: 0.2823 - val_accuracy: 0.9141\n",
            "Epoch 7/10\n",
            "145/145 [==============================] - 10s 71ms/step - loss: 0.0915 - accuracy: 0.9742 - val_loss: 0.3264 - val_accuracy: 0.9115\n",
            "Epoch 8/10\n",
            "145/145 [==============================] - 10s 69ms/step - loss: 0.0703 - accuracy: 0.9816 - val_loss: 0.3343 - val_accuracy: 0.9130\n",
            "Epoch 9/10\n",
            "145/145 [==============================] - 10s 70ms/step - loss: 0.0537 - accuracy: 0.9874 - val_loss: 0.3435 - val_accuracy: 0.9146\n",
            "Epoch 10/10\n",
            "145/145 [==============================] - 10s 70ms/step - loss: 0.0408 - accuracy: 0.9900 - val_loss: 0.3936 - val_accuracy: 0.9172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhssOSNGnPoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d99211-a4fd-4749-d87b-a3f5eb6834b8"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset_batched_tf)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "37/37 [==============================] - 1s 16ms/step - loss: 0.3950 - accuracy: 0.9181\n",
            "Test Loss: 0.3949778378009796\n",
            "Test Accuracy: 0.9181463718414307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ems-08GnPrT"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XV5sS5hrj2OZ",
        "outputId": "789f886b-eaff-4b94-c206-b1c434966440"
      },
      "source": [
        "\n",
        "sample_text = ('good it\\'s great')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('bad. It\\'s very bad. Worse')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('This airlines is the best')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I will never fly with you')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "sample_text = ('I will never recommend you')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I will always recommend you')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "sample_text = ('Will be a long time before I recommend you to anyone.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I liked the way you guys organize yourself')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.4241579]]\n",
            "[[-3.679005]]\n",
            "[[1.5192201]]\n",
            "[[-1.4085932]]\n",
            "[[-0.5680525]]\n",
            "[[1.4155738]]\n",
            "[[-3.8368037]]\n",
            "[[0.36423916]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJLXFg1hYdxz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmnYrHqH21Fs",
        "outputId": "647aced5-c927-4251-f9c1-e5aefe5b04d3"
      },
      "source": [
        "model.set_weights"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Layer.set_weights of <keras.engine.sequential.Sequential object at 0x7fe04a56a410>>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCvh8B7s4B42"
      },
      "source": [
        "encoder_new= None\n",
        "encoder_new = tf.keras.layers.TextVectorization()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yySQJS9q4B7b",
        "outputId": "643a4ccc-b6cd-4184-ee05-a1e7f9320eac"
      },
      "source": [
        "encoder_new.get_config()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': None,\n",
              " 'name': 'text_vectorization_1',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': None,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpGDlOui4B9_"
      },
      "source": [
        "encoder_new.adapt(np.array([['hell']], dtype=np.object), batch_size=None)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hru6iWc4CAt"
      },
      "source": [
        "encoder_new.set_weights(encoder.get_weights())"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97AkBpba4IZe",
        "outputId": "8543faa2-a2b2-47f1-908d-d39ae3a4d319"
      },
      "source": [
        "encoder(\"hello world\").numpy()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([977, 754])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yziygrTt4IgA",
        "outputId": "465247c0-a396-4069-f9bc-167c99022e3d"
      },
      "source": [
        "encoder_new(\"hello world\").numpy()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([977, 754])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL0DTsx32HE8"
      },
      "source": [
        "model2 = tf.keras.Sequential([\n",
        "      encoder,\n",
        "      tf.keras.layers.Embedding(\n",
        "          input_dim=len(encoder.get_vocabulary()),\n",
        "          output_dim=64,\n",
        "          # Use masking to handle the variable sequence lengths\n",
        "          mask_zero=True),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "      tf.keras.layers.Dense(16, activation='relu'),\n",
        "      tf.keras.layers.Dense(8, activation='relu'),\n",
        "      tf.keras.layers.Dense(1) #, activation='sigmoid')\n",
        "  ])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SU45cEp6GHr"
      },
      "source": [
        "model2.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy']) #run_eagerly=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-BcsfIb6Ph3"
      },
      "source": [
        "layers = []\n",
        "for layer in model.layers:\n",
        "  layers.append(layer.get_weights())"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tn6RNJn2HII",
        "outputId": "855faef9-253e-42d6-85cb-f070fdcbfff9"
      },
      "source": [
        "i  = 0\n",
        "for layer in model2.layers:\n",
        "  # if i == 0:\n",
        "  #   i += 1\n",
        "  #   continue\n",
        "  print(layer.get_weights()[0].dtype)\n",
        "  layer.set_weights(layers[i])\n",
        "  i += 1"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7MFY3BF2HKZ",
        "outputId": "adcfc634-6983-46e4-e7b0-eb5d3f5798f9"
      },
      "source": [
        "sample_text = ('good it\\'s great')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('bad. It\\'s very bad. Worse')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('This airlines is the best')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I will never fly with you')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "sample_text = ('I will never recommend you')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I will always recommend you')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "sample_text = ('Will be a long time before I recommend you to anyone.')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I liked the way you guys organize yourself')\n",
        "predictions = model2.predict(np.array([sample_text]))\n",
        "print(predictions)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.4241579]]\n",
            "[[-3.679005]]\n",
            "[[1.5192201]]\n",
            "[[-1.4085932]]\n",
            "[[-0.5680525]]\n",
            "[[1.4155738]]\n",
            "[[-3.8368037]]\n",
            "[[0.36423916]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xphrGuWhSzq"
      },
      "source": [
        "import json\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp0ILYuRe4pa"
      },
      "source": [
        "class NdarrayEncoder(json.JSONEncoder):\n",
        "  def default(self, obj):\n",
        "    if isinstance(obj, np.ndarray):\n",
        "      return obj.tolist()\n",
        "    if isinstance(obj, bytes):\n",
        "      return obj.decode('utf-8')\n",
        "    print(obj)\n",
        "    return json.JSONEncoder().default(self, obj)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izkBYRhs57bY"
      },
      "source": [
        "layersInList = []\n",
        "\n",
        "for layer in model.layers:\n",
        "  layersInList.append(layer.get_weights())"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kCNJ50557gs"
      },
      "source": [
        "weightsInJson = json.dumps(layersInList, cls=NdarrayEncoder)\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIFlS2GGzR8I"
      },
      "source": [
        "with open(\"weights.json\", \"w\") as json_file:\n",
        "  json_file.write(weightsInJson)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTAdvw1K0U3Y"
      },
      "source": [
        "with open(\"weights.json\", \"r\") as json_file_r:\n",
        "  weightsInListRead = json_file_r.read()"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mE9L6Nxp0-a7"
      },
      "source": [
        "weightsReadData = json.loads(weightsInListRead)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW_mfwtZ2d2J"
      },
      "source": [
        "# def isIterable(obj):\n",
        "#   if hasattr(obj, '__iter__') and hasattr(obj, '__next__') and hasattr('__getitem__'):\n",
        "#     return True\n",
        "#   return False\n",
        "\n",
        "def convertStringToBytesInObject(convertableObj):\n",
        "  if isinstance(convertableObj, list):\n",
        "    i = 0\n",
        "    for item in convertableObj:\n",
        "      if isinstance(item, str):\n",
        "        convertableObj[i] = item.encode()\n",
        "      elif isinstance(item, list): \n",
        "        convertStringToBytesInObject(item)\n",
        "      i += 1\n",
        "  else:\n",
        "    print(convertableObj)\n",
        "    raise Exception(\" expected to be iterable \")\n",
        "\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQdAk0GV7EVD",
        "outputId": "833cc779-472c-4d5a-8745-dc982fa8cd3d"
      },
      "source": [
        "isIterable([])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P973ss02TSs"
      },
      "source": [
        "# convertStringToBytesInObject(weightsReadData)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLBJMsaQ8CWr"
      },
      "source": [
        "encoder_new= None\n",
        "encoder_new = tf.keras.layers.TextVectorization()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSYQYtqC8tKu",
        "outputId": "ccc36c31-19bd-4c97-dd96-00b82ada1295"
      },
      "source": [
        "encoder_new.get_config()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': None,\n",
              " 'name': 'text_vectorization_3',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': None,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt6P4JhQ8tN6"
      },
      "source": [
        "encoder_new.adapt(np.array([['hell']], dtype=np.object), batch_size=None)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8l0P78j8tQ5"
      },
      "source": [
        "encoder_new.set_weights(weightsReadData[0])"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSLPaJBA8tT3",
        "outputId": "89f51102-de5c-4e8f-d525-5d9605b4d6a8"
      },
      "source": [
        "encoder_new(\"hello world\").numpy()"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([977, 754])"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2ttsgys8-vo",
        "outputId": "8e0f4e69-1cf5-4b32-cda7-11ec073718d1"
      },
      "source": [
        "encoder(\"hello world\").numpy()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([977, 754])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulBM5LWi8-37"
      },
      "source": [
        ""
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjIef2a-8Hdw"
      },
      "source": [
        "model3 = tf.keras.Sequential([\n",
        "      encoder_new,\n",
        "      tf.keras.layers.Embedding(\n",
        "          input_dim=len(encoder_new.get_vocabulary()),\n",
        "          output_dim=64,\n",
        "          # Use masking to handle the variable sequence lengths\n",
        "          mask_zero=True),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(32, activation='relu'),\n",
        "      tf.keras.layers.Dense(16, activation='relu'),\n",
        "      tf.keras.layers.Dense(8, activation='relu'),\n",
        "      tf.keras.layers.Dense(1) #, activation='sigmoid')\n",
        "  ])"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i2pkw8E8HgY"
      },
      "source": [
        "model3.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy']) #run_eagerly=True)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L3XQB-a9rVY",
        "outputId": "9c85b5c7-d71b-4192-eb14-3dadecbd18fa"
      },
      "source": [
        "layers2 = []\n",
        "for layerWeights in weightsReadData:\n",
        "  layers2.append(layerWeights)\n",
        "  print(len(layerWeights))"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "6\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ4jvI7OExbU"
      },
      "source": [
        "def convertToNdarray(obj):\n",
        "  if isinstance(obj, list):\n",
        "    return np.asarray([convertToNdarray(o) for o in obj])\n",
        "  else:\n",
        "    return obj\n"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwMJ_rCF6EK",
        "outputId": "bdafbf04-6e91-48f0-d199-988d4a37843b"
      },
      "source": [
        "layers2 = convertToNdarray(layers2)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fPjIB7pC56a"
      },
      "source": [
        "layers2 = [np.array(layer, dtype=object) for layer in layers2]"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVqES1Il8HjK",
        "outputId": "aa0bc1e1-d58b-4fde-e697-7787afd04b6e"
      },
      "source": [
        "i  = 0\n",
        "for layer in model3.layers:\n",
        "  # if i == 0:\n",
        "  #   i += 1\n",
        "  #   continue\n",
        "  print(layer.get_weights()[0].dtype)\n",
        "  layer.set_weights(layers2[i])\n",
        "  i += 1"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qN5Gs2UBvxU",
        "outputId": "27e1638c-db5a-465b-c567-89e4366f4a4b"
      },
      "source": [
        "sample_text = ('good it\\'s great')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('bad. It\\'s very bad. Worse')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('This airlines is the best')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I will never fly with you')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "sample_text = ('I will never recommend you')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I will always recommend you')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "\n",
        "sample_text = ('Will be a long time before I recommend you to anyone.')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('I liked the way you guys organize yourself')\n",
        "predictions = model3.predict(np.array([sample_text]))\n",
        "print(predictions)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.4241579]]\n",
            "[[-3.679005]]\n",
            "[[1.5192201]]\n",
            "[[-1.4085932]]\n",
            "[[-0.5680525]]\n",
            "[[1.4155738]]\n",
            "[[-3.8368037]]\n",
            "[[0.36423916]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-55PbSEQGIDf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkCQmqoqGIH6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6qGu4s8GILu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JB1Da6xGIPx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-vPXF2CB0rq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFAbz8kv9Uvm",
        "outputId": "45b22e9e-9aa1-4492-9689-a88e707b4127"
      },
      "source": [
        "len(weightsReadData)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpcIsx679Uy0",
        "outputId": "ec5fdd16-a0a9-43e5-eb58-e6a50776cd90"
      },
      "source": [
        "len(model3.layers)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26QupXGI8Hl2",
        "outputId": "4ec9c917-1b2e-480c-f20c-8a9f69dd7040"
      },
      "source": [
        "len(weightsReadData[2])"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AolxoLuc_LDV",
        "outputId": "6c886e1f-0e0c-494f-b35a-16d779809de8"
      },
      "source": [
        "len(model3.layers[2].get_weights())"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4c3pG3p_cEW",
        "outputId": "290e17f8-dd7d-478a-f98e-b5213dacfa47"
      },
      "source": [
        "len(model2.layers[2].get_weights())"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPYbuySumb1R"
      },
      "source": [
        "hw = b'hello world'"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qvUs6Wb57iw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a25292b9-e2bf-465d-d48b-196dd17e08a9"
      },
      "source": [
        "json.dumps(hw.decode('utf-8'))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\"hello world\"'"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FBMQtcA57k-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yneRS2mz57nE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6raXwJRw57pF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UjD2NCN57rL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUTNyYuu57tc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGDNfaNW57vc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYrTniOVYd0G",
        "outputId": "a3f926a9-ef9a-4cb1-92c3-61f9e8b778de"
      },
      "source": [
        "tf.keras.layers.serialize(encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_name': 'TextVectorization',\n",
              " 'config': {'batch_input_shape': (None,),\n",
              "  'dtype': 'string',\n",
              "  'max_tokens': None,\n",
              "  'name': 'text_vectorization_2',\n",
              "  'ngrams': None,\n",
              "  'output_mode': 'int',\n",
              "  'output_sequence_length': None,\n",
              "  'pad_to_max_tokens': False,\n",
              "  'split': 'whitespace',\n",
              "  'standardize': 'lower_and_strip_punctuation',\n",
              "  'trainable': True}}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_iKZfPJYd2z",
        "outputId": "8f548174-cc57-4fad-adfd-286d917bd6da"
      },
      "source": [
        "encoder.get_weights()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([b'to', b'the', b'i', ..., b'021mbps', b'0162431184663',\n",
              "        b'0162389030167'], dtype=object)]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8wcR6W0Yd5K"
      },
      "source": [
        "encoder_new= None\n",
        "encoder_new = tf.keras.layers.TextVectorization()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHkcxD3ffXyA",
        "outputId": "568b9780-4fdb-4faf-91cb-0763b37acc6c"
      },
      "source": [
        "encoder_new.get_config()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dtype': 'string',\n",
              " 'max_tokens': None,\n",
              " 'name': 'text_vectorization_8',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': None,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True}"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hicKBkLSfjzC"
      },
      "source": [
        "encoder_new.adapt([['hell']], batch_size=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIf948LGYd79"
      },
      "source": [
        "encoder_new.set_weights(encoder.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eY5KhRREbF5-"
      },
      "source": [
        "# encoder_new.set_vocabulary(encoder.get_vocabulary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3gY0JI3Yd-k",
        "outputId": "28855b2c-5b10-4870-f2f5-9342d54b04c7"
      },
      "source": [
        "encoder(\"hello world\").numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1056,  701])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXEb8fUrcJof",
        "outputId": "cb3370f6-f258-4814-ebb5-da68106e4e46"
      },
      "source": [
        "encoder_new(\"hello world\").numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1056,  701])"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXUNytAtkvSs"
      },
      "source": [
        "dataset_train_batched_text = np.array_split(dataset_train['text'],len(dataset_train['text'])/BATCH_SIZE)\n",
        "dataset_train_batched_class = np.array_split(dataset_train['airline_sentiment'], len(dataset_train['airline_sentiment'])/BATCH_SIZE)\n",
        "\n",
        "dataset_test_batched_text = np.array_split(dataset_test['text'],len(dataset_test['text'])/BATCH_SIZE)\n",
        "dataset_test_batched_class = np.array_split(dataset_test['airline_sentiment'], len(dataset_test['airline_sentiment'])/BATCH_SIZE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrfzJOjCpfrm",
        "outputId": "10322421-c808-40eb-8178-7e8ae67a7ad9"
      },
      "source": [
        "print (len(dataset_train))\n",
        "print (len(dataset_test))\n",
        "print (\" ------------------------  \")\n",
        "print (len(dataset_train_batched_text))\n",
        "print (len(dataset_train_batched_class))\n",
        "print (len(dataset_train_batched_text[len(dataset_train_batched_text)- 1]))\n",
        "print (len(dataset_train_batched_class[len(dataset_train_batched_text)- 1]))\n",
        "print (\" ------------------------  \")\n",
        "print (len(dataset_test_batched_text))\n",
        "print (len(dataset_test_batched_class))\n",
        "print (len(dataset_test_batched_text[len(dataset_test_batched_text)- 1]))\n",
        "print (len(dataset_test_batched_class[len(dataset_test_batched_class)- 1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9232\n",
            "2309\n",
            " ------------------------  \n",
            "144\n",
            "144\n",
            "64\n",
            "64\n",
            " ------------------------  \n",
            "36\n",
            "36\n",
            "64\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "YSrMRgxrHZGs",
        "outputId": "3796870b-ad58-4fd1-80d6-8b79bc5b174e"
      },
      "source": [
        "dataset_test_batched_text_tmp =  np.asarray(dataset_test_batched_text, dtype=object)\n",
        "dataset_test_batched_class_tmp = np.asarray(dataset_test_batched_class, dtype=object)\n",
        "\n",
        "dataset_train_batched_text_tmp =  np.asarray(dataset_train_batched_text, dtype=object)\n",
        "dataset_train_batched_class_tmp = np.asarray(dataset_train_batched_class, dtype=object)\n",
        "\n",
        "np_dataset_test_batched_text = []\n",
        "np_dataset_test_batched_class = []\n",
        "np_dataset_train_batched_text = []\n",
        "np_dataset_train_batched_class = []\n",
        "\n",
        "for itr in dataset_test_batched_text_tmp:\n",
        "  np_dataset_test_batched_text.append(itr.to_numpy())\n",
        "\n",
        "for itr in dataset_test_batched_class_tmp:\n",
        "  np_dataset_test_batched_class.append(itr.to_numpy())\n",
        "\n",
        "\n",
        "for itr in dataset_train_batched_text_tmp:\n",
        "  np_dataset_train_batched_text.append(itr.to_numpy())\n",
        "\n",
        "for itr in dataset_train_batched_class_tmp:\n",
        "  np_dataset_train_batched_class.append(itr.to_numpy())\n",
        "\n",
        "\n",
        "np_dataset_test_batched_text = np.asarray(np_dataset_test_batched_text, dtype=object)\n",
        "np_dataset_test_batched_class = np.asarray(np_dataset_test_batched_class, dtype=object)\n",
        "np_dataset_train_batched_text = np.asarray(np_dataset_train_batched_text, dtype=object)\n",
        "np_dataset_train_batched_class = np.asarray(np_dataset_train_batched_class, dtype=object)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot convert the series to {converter}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot convert the series to <class 'float'>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-94ddb91940d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_test_batched_text_tmp\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test_batched_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset_test_batched_class_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_test_batched_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_train_batched_text_tmp\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train_batched_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset_train_batched_class_tmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train_batched_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "F71YmsZ0Li0p",
        "outputId": "88e65a2f-3b45-4987-85db-83750a65cc5c"
      },
      "source": [
        "np_dataset_test_batched_text[len(np_dataset_test_batched_text)- 1][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'used to love you, but you keep rescheduling my flights.  #southworst'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "Ae9oYmHHQ4td",
        "outputId": "3d88dce7-5403-4939-c51e-90141490c16b"
      },
      "source": [
        "tf_dataset_test_batched_text = tf.data.Dataset.from_tensor_slices(np_dataset_test_batched_text)\n",
        "tf_dataset_test_batched_text\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-d71ba3a8a08a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_dataset_test_batched_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_dataset_test_batched_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf_dataset_test_batched_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \"\"\"\n\u001b[0;32m--> 685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3842\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3843\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3844\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3845\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3846\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    127\u001b[0m           \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m           normalized_components.append(\n\u001b[0;32m--> 129\u001b[0;31m               ops.convert_to_tensor(t, name=\"component_%d\" % i, dtype=dtype))\n\u001b[0m\u001b[1;32m    130\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpack_as\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "kjO0TYR8MWtw",
        "outputId": "4127f206-5cad-4ed0-944f-4116fa75032b"
      },
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.TextVectorization()\n",
        "    #max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(np_dataset_train_batched_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-25586f845400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextVectorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#max_tokens=VOCAB_SIZE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_dataset_train_batched_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[0;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0msteps_per_execution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         distribute=False)\n\u001b[0m\u001b[1;32m    244\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_adapt_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m                **kwargs):\n\u001b[1;32m    229\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[1;32m    232\u001b[0m         sample_weights, sample_weight_modes)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0m_is_scipy_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[1;32m   1430\u001b[0m   return convert_to_tensor_v2(\n\u001b[0;32m-> 1431\u001b[0;31m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[0m\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1439\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLZkM_dySZy0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_graphs(history, metric):\n",
        "  plt.plot(history.history[metric])\n",
        "  plt.plot(history.history['val_'+metric], '')\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(metric)\n",
        "  plt.legend([metric, 'val_'+metric])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH9mEfHsTUZT",
        "outputId": "2a8682b3-26e8-4a6e-f0d2-c8faf198815a"
      },
      "source": [
        "dataset_2, info = tfds.load('imdb_reviews', with_info=True,\n",
        "                          as_supervised=True)\n",
        "train_dataset, test_dataset = dataset_2['train'], dataset_2['test']\n",
        "\n",
        "train_dataset.element_spec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorSpec(shape=(), dtype=tf.string, name=None),\n",
              " TensorSpec(shape=(), dtype=tf.int64, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EfbsPwLvXSq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uw5vxXo1UInm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9PJDOYpTVCR",
        "outputId": "e61daf21-fcf9-4044-c6f2-0f342fdd4507"
      },
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('text: ', example.numpy())\n",
        "  print('label: ', label.numpy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "label:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6n1iiUfTYMv"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1d_GCcUTaWz"
      },
      "source": [
        "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu5pc-10veLl",
        "outputId": "fd5de364-d529-4c75-8a9a-876d1328723d"
      },
      "source": [
        "train_dataset.as_numpy_iterator()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9ME5GFTTckO",
        "outputId": "2e311f28-074d-4c55-deb9-71461888916e"
      },
      "source": [
        "for example, label in train_dataset.take(1):\n",
        "  print('texts: ', example.numpy()[:3])\n",
        "  print()\n",
        "  print('labels: ', label.numpy()[:])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texts:  [b\"Eleven different Film Makers from different parts of the world are assembled in this film to present their views and ideas about the WTC attack. This is one of the best effort you will see in any Film. Films like this are rarely made and appreciated. This film tries to touch every possible core of WTC. Here are some of the most important stories from the film that makes this film so unique.<br /><br />There is the story from Samira Makhmalbaf (Iran) where somewhere in Iran people are preparing for the attacks from America. There a teacher is trying to educate her students by informing them about Innocent People being killed in WTC massacre. Then comes a story from Youssef Chahine (Egypt) where a Film Maker comes across face-to-face conversation with a Dead Soldier in the WTC attack and a Dead Hard Core Terrorist who was involved in WTC attack. Then we see a story from Idrissa Ouedraogo (Burkina Faso) where a group of Five Innocent children's sees Osama Bin Laden and plans to kidnap him and win the reward money from America. Then we see the story from Alejandro Gozalez Inarritu (Mexico) where you see a Black Screen and slowly you see the real footage of WTC buildings coming down. And the people who are stuck in the building are jumping out of it to save their lives. The other most important story is from Mira Nair (India) where a mother is struggling to get respect for her Dead Son whose name is falsely trapped in WTC massacre! After September 11 attack, Our heart beat automatically starts pumping if we hear two names anywhere in the world.. First is World Trade Centre and the second is Osama! This film totally changes our perception and makes a strong point by claiming something more to it.<br /><br />I will definitely recommend this movie to everyone who loves to have such kinds of Home DVD Collection. Definitely worth every penny you spend. But please don't expect anything more apart from Films in this DVD. There is of course Filmographies of the Film Makers but No Extra Features.\"\n",
            " b\"Interesting to read comments by viewers regarding Omega Code... many of the overwhelmingly positive comments were lifted almost word for word from TBN broadcasts... the movie looks as if it were made to go directly to video, to be stocked besides the three-part rapture series that was done by some other religious group in the 70s.. dont remember it? You wont remember this one either in a year or two. This is the first movie I have ever seen where it was implied that it was your religious duty to go to it and buy as many tickets as possible to save souls... very shameful... this just goes to show that if you are a televangelist's son, you too can play high-roller Hollywood producer with lil ole ladies tithe money...\"\n",
            " b\"While this film certainly does possess the stench of a bad film, it's surprisingly watchable on several levels. First, for old movie fans, it's interesting to see the leading role played by Dean Jagger (no relation to Mick). While Jagger later went on to a very respectable role as a supporting actor (even garnering the Oscar in this category for 12 O'CLOCK HIGH), here his performance is truly unique since he actually has a full head of hair (I never saw him this way before) and because he was by far the worst actor in the film. This film just goes to show that if an actor cannot act in his earlier films doesn't mean he can't eventually learn to be a great actor. Another good example of this phenomenon is Paul Newman, whose first movie (THE SILVER CHALICE) is considered one of the worst films of the 1950s.<br /><br />A second reason to watch the film is the shear cheesiness of it all. The writing is bad, the acting is bad and the special effects are bad. For example, when Jagger and an unnamed Cambodian are wading through the water, it's obvious they are really just walking in place and the background is poorly projected behind them. Plus, once they leave the water, their costumes are 100% dry!!! Horrid continuity and mindlessly bad dialog abounds throughout the film--so much so that it's hard to imagine why they didn't ask Bela Lugosi or George Zucco to star in the film--since both of them starred in many grade-z horror films. In many ways, this would be a perfect example for a film class on how NOT to make a film.<br /><br />So, while giving it a 3 is probably a bit over-generous, it's fun to laugh at and short so it's worth a look for bad film fans.\"]\n",
            "\n",
            "labels:  [1 0 0 0 0 1 1 0 1 0 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 1 0 1\n",
            " 1 1 0 0 1 0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5k5pBe1TeMR"
      },
      "source": [
        "VOCAB_SIZE = 1000\n",
        "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
        "    max_tokens=VOCAB_SIZE)\n",
        "encoder.adapt(train_dataset.map(lambda text, label: text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-OCu3rSTkL0"
      },
      "source": [
        "vocab = np.array(encoder.get_vocabulary())\n",
        "vocab[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovH6eqZAVf5i",
        "outputId": "1e070ecb-7488-4163-d965-4e2654ae321e"
      },
      "source": [
        "encoded_example = encoder(example)[:3].numpy()\n",
        "encoded_example"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  1, 267,  20, ...,   0,   0,   0],\n",
              "       [218,   6, 321, ...,   0,   0,   0],\n",
              "       [131,  11,  20, ...,   0,   0,   0]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3USCNIEVy1B",
        "outputId": "6dd4ab7a-e30f-434e-83f9-ed2929fcc1ff"
      },
      "source": [
        "for n in range(3):\n",
        "  print(\"Original: \", example[n].numpy())\n",
        "  print(\"Round-trip: \", \" \".join(vocab[encoded_example[n]]))\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  b\"Eleven different Film Makers from different parts of the world are assembled in this film to present their views and ideas about the WTC attack. This is one of the best effort you will see in any Film. Films like this are rarely made and appreciated. This film tries to touch every possible core of WTC. Here are some of the most important stories from the film that makes this film so unique.<br /><br />There is the story from Samira Makhmalbaf (Iran) where somewhere in Iran people are preparing for the attacks from America. There a teacher is trying to educate her students by informing them about Innocent People being killed in WTC massacre. Then comes a story from Youssef Chahine (Egypt) where a Film Maker comes across face-to-face conversation with a Dead Soldier in the WTC attack and a Dead Hard Core Terrorist who was involved in WTC attack. Then we see a story from Idrissa Ouedraogo (Burkina Faso) where a group of Five Innocent children's sees Osama Bin Laden and plans to kidnap him and win the reward money from America. Then we see the story from Alejandro Gozalez Inarritu (Mexico) where you see a Black Screen and slowly you see the real footage of WTC buildings coming down. And the people who are stuck in the building are jumping out of it to save their lives. The other most important story is from Mira Nair (India) where a mother is struggling to get respect for her Dead Son whose name is falsely trapped in WTC massacre! After September 11 attack, Our heart beat automatically starts pumping if we hear two names anywhere in the world.. First is World Trade Centre and the second is Osama! This film totally changes our perception and makes a strong point by claiming something more to it.<br /><br />I will definitely recommend this movie to everyone who loves to have such kinds of Home DVD Collection. Definitely worth every penny you spend. But please don't expect anything more apart from Films in this DVD. There is of course Filmographies of the Film Makers but No Extra Features.\"\n",
            "Round-trip:  [UNK] different film [UNK] from different parts of the world are [UNK] in this film to present their [UNK] and ideas about the [UNK] [UNK] this is one of the best effort you will see in any film films like this are [UNK] made and [UNK] this film tries to [UNK] every possible [UNK] of [UNK] here are some of the most important stories from the film that makes this film so [UNK] br there is the story from [UNK] [UNK] [UNK] where [UNK] in [UNK] people are [UNK] for the [UNK] from america there a [UNK] is trying to [UNK] her [UNK] by [UNK] them about [UNK] people being killed in [UNK] [UNK] then comes a story from [UNK] [UNK] [UNK] where a film [UNK] comes across [UNK] [UNK] with a dead [UNK] in the [UNK] [UNK] and a dead hard [UNK] [UNK] who was involved in [UNK] [UNK] then we see a story from [UNK] [UNK] [UNK] [UNK] where a group of five [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] and [UNK] to [UNK] him and [UNK] the [UNK] money from america then we see the story from [UNK] [UNK] [UNK] [UNK] where you see a black screen and [UNK] you see the real footage of [UNK] [UNK] coming down and the people who are [UNK] in the [UNK] are [UNK] out of it to save their lives the other most important story is from [UNK] [UNK] [UNK] where a mother is [UNK] to get [UNK] for her dead son whose name is [UNK] [UNK] in [UNK] [UNK] after [UNK] [UNK] [UNK] our heart [UNK] [UNK] starts [UNK] if we hear two [UNK] [UNK] in the world first is world [UNK] [UNK] and the second is [UNK] this film totally [UNK] our [UNK] and makes a strong point by [UNK] something more to itbr br i will definitely recommend this movie to everyone who [UNK] to have such [UNK] of home dvd [UNK] definitely worth every [UNK] you [UNK] but please dont expect anything more apart from films in this dvd there is of course [UNK] of the film [UNK] but no [UNK] features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            "\n",
            "Original:  b\"Interesting to read comments by viewers regarding Omega Code... many of the overwhelmingly positive comments were lifted almost word for word from TBN broadcasts... the movie looks as if it were made to go directly to video, to be stocked besides the three-part rapture series that was done by some other religious group in the 70s.. dont remember it? You wont remember this one either in a year or two. This is the first movie I have ever seen where it was implied that it was your religious duty to go to it and buy as many tickets as possible to save souls... very shameful... this just goes to show that if you are a televangelist's son, you too can play high-roller Hollywood producer with lil ole ladies tithe money...\"\n",
            "Round-trip:  interesting to read comments by viewers [UNK] [UNK] [UNK] many of the [UNK] [UNK] comments were [UNK] almost word for word from [UNK] [UNK] the movie looks as if it were made to go [UNK] to video to be [UNK] [UNK] the [UNK] [UNK] series that was done by some other [UNK] group in the 70s dont remember it you wont remember this one either in a year or two this is the first movie i have ever seen where it was [UNK] that it was your [UNK] [UNK] to go to it and buy as many [UNK] as possible to save [UNK] very [UNK] this just goes to show that if you are a [UNK] son you too can play [UNK] hollywood [UNK] with [UNK] [UNK] [UNK] [UNK] money                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
            "\n",
            "Original:  b\"While this film certainly does possess the stench of a bad film, it's surprisingly watchable on several levels. First, for old movie fans, it's interesting to see the leading role played by Dean Jagger (no relation to Mick). While Jagger later went on to a very respectable role as a supporting actor (even garnering the Oscar in this category for 12 O'CLOCK HIGH), here his performance is truly unique since he actually has a full head of hair (I never saw him this way before) and because he was by far the worst actor in the film. This film just goes to show that if an actor cannot act in his earlier films doesn't mean he can't eventually learn to be a great actor. Another good example of this phenomenon is Paul Newman, whose first movie (THE SILVER CHALICE) is considered one of the worst films of the 1950s.<br /><br />A second reason to watch the film is the shear cheesiness of it all. The writing is bad, the acting is bad and the special effects are bad. For example, when Jagger and an unnamed Cambodian are wading through the water, it's obvious they are really just walking in place and the background is poorly projected behind them. Plus, once they leave the water, their costumes are 100% dry!!! Horrid continuity and mindlessly bad dialog abounds throughout the film--so much so that it's hard to imagine why they didn't ask Bela Lugosi or George Zucco to star in the film--since both of them starred in many grade-z horror films. In many ways, this would be a perfect example for a film class on how NOT to make a film.<br /><br />So, while giving it a 3 is probably a bit over-generous, it's fun to laugh at and short so it's worth a look for bad film fans.\"\n",
            "Round-trip:  while this film certainly does [UNK] the [UNK] of a bad film its [UNK] [UNK] on several [UNK] first for old movie fans its interesting to see the leading role played by [UNK] [UNK] no [UNK] to [UNK] while [UNK] later went on to a very [UNK] role as a supporting actor even [UNK] the oscar in this [UNK] for [UNK] [UNK] high here his performance is truly unique since he actually has a full head of [UNK] i never saw him this way before and because he was by far the worst actor in the film this film just goes to show that if an actor cannot act in his earlier films doesnt mean he cant eventually learn to be a great actor another good example of this [UNK] is paul [UNK] whose first movie the [UNK] [UNK] is [UNK] one of the worst films of the [UNK] br a second reason to watch the film is the [UNK] [UNK] of it all the writing is bad the acting is bad and the special effects are bad for example when [UNK] and an [UNK] [UNK] are [UNK] through the [UNK] its obvious they are really just [UNK] in place and the background is poorly [UNK] behind them plus once they leave the [UNK] their [UNK] are [UNK] [UNK] [UNK] [UNK] and [UNK] bad dialog [UNK] throughout the [UNK] much so that its hard to imagine why they didnt ask [UNK] [UNK] or george [UNK] to star in the [UNK] both of them [UNK] in many [UNK] horror films in many ways this would be a perfect example for a film class on how not to make a filmbr br so while giving it a 3 is probably a bit [UNK] its fun to laugh at and short so its worth a look for bad film fans                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXB3qGToM3Q0"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJXcboOdV0yS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "0a7b4da9-3c34-4476-e11e-504ceffd7a9f"
      },
      "source": [
        "import os\n",
        "model2 = None\n",
        "print(os.listdir('/content/drive/MyDrive/sentiment/'))\n",
        "if len(os.listdir('/content/drive/MyDrive/sentiment/')) == 0:\n",
        "  model = tf.keras.Sequential([\n",
        "      encoder,\n",
        "      tf.keras.layers.Embedding(\n",
        "          input_dim=len(encoder.get_vocabulary()),\n",
        "          output_dim=64,\n",
        "          # Use masking to handle the variable sequence lengths\n",
        "          mask_zero=True),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "  ])\n",
        "  print (\"created model\")\n",
        "else:\n",
        "  model2 = tf.keras.models.load_model (\"/content/drive/MyDrive/sentiment/\")\n",
        "  print (\"loaded model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['variables', 'assets', 'saved_model.pb', 'keras_metadata.pb']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-9add8efec2c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"created model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/sentiment/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   raise IOError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, compile, options)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   \u001b[0;31m# Finalize the loaded layers and remove the extra tracked dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m   \u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m   \u001b[0mkeras_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdel_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36mfinalize_objects\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0;31m# Initialize graph networks, now that layer dependencies have been resolved.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reconstruct_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_unblock_model_reconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_reconstruct_all_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    661\u001b[0m       \u001b[0mall_initialized_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_layer_dependencies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reconstruct_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m       \u001b[0m_finalize_config_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/saved_model/load.py\u001b[0m in \u001b[0;36m_reconstruct_model\u001b[0;34m(self, model_id, model, layers)\u001b[0m\n\u001b[1;32m    696\u001b[0m               \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m               name=layers[0].name + '_input'))\n\u001b[0;32m--> 698\u001b[0;31m       \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mfirst_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_child_layer_node_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    215\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 977\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1113\u001b[0m       \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m       outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1115\u001b[0;31m           inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m           \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/wrappers.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask, initial_state, constants)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m       y = self.forward_layer(forward_inputs,\n\u001b[0;32m--> 699\u001b[0;31m                              initial_state=forward_state, **kwargs)\n\u001b[0m\u001b[1;32m    700\u001b[0m       y_rev = self.backward_layer(backward_inputs,\n\u001b[1;32m    701\u001b[0m                                   initial_state=backward_state, **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[1;32m   1036\u001b[0m             self._compute_dtype_object):\n\u001b[0;32m-> 1037\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_inputs_if_ragged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0mis_ragged_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow_lengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_args_if_ragged\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_ragged_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;31m# LSTM does not support constants. Ignore it during process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_validate_args_if_ragged\u001b[0;34m(self, is_ragged_input, mask)\u001b[0m\n\u001b[1;32m    871\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m       raise ValueError('The mask that was passed in was ' + str(mask) +\n\u001b[0;32m--> 873\u001b[0;31m                        \u001b[0;34m' and cannot be applied to RaggedTensor inputs. Please '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m                        \u001b[0;34m'make sure that there is no mask passed in by upstream '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                        'layers.')\n",
            "\u001b[0;31mValueError\u001b[0m: The mask that was passed in was tf.RaggedTensor(values=Tensor(\"Placeholder_2:0\", shape=(None,), dtype=bool), row_splits=Tensor(\"Placeholder_3:0\", shape=(None,), dtype=int64)) and cannot be applied to RaggedTensor inputs. Please make sure that there is no mask passed in by upstream layers."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NCMVgnysDcL"
      },
      "source": [
        "if model2 is not None:\n",
        "  model = model2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTjPhtfcV4ES",
        "outputId": "397c42fb-3a4f-4d46-eb23-e41f6f4a3b97"
      },
      "source": [
        "print([layer.supports_masking for layer in model.layers])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False, True, True, True, True]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC6oQgrCV5od",
        "outputId": "5f7f5eba-287e-40d0-c922-584e04a7ed42"
      },
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa5d69c5320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fa5d69c5320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5011921]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc_CWY97V7BC",
        "outputId": "720a48c0-8db9-4206-a8ad-31b6520c4d1c"
      },
      "source": [
        "# predict on a sample text with padding\n",
        "\n",
        "padding = \"the \" * 2000\n",
        "predictions = model.predict(np.array([sample_text, padding]))\n",
        "print(predictions[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5011921]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEVQzpW88g6s"
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy']) #run_eagerly=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBpzPh93WMvP",
        "outputId": "a7f960dd-6fad-4192-89e1-d392a6fc1fdf"
      },
      "source": [
        "history = model.fit(train_dataset, epochs=5,\n",
        "                    validation_data=test_dataset,\n",
        "                    validation_steps=30)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 112s 285ms/step - loss: 0.6542 - accuracy: 0.6130 - val_loss: 0.5631 - val_accuracy: 0.7479\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 110s 279ms/step - loss: 0.4339 - accuracy: 0.8212 - val_loss: 0.4028 - val_accuracy: 0.8385\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 110s 280ms/step - loss: 0.3584 - accuracy: 0.8520 - val_loss: 0.3456 - val_accuracy: 0.8615\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 108s 274ms/step - loss: 0.3338 - accuracy: 0.8620 - val_loss: 0.3362 - val_accuracy: 0.8615\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 107s 271ms/step - loss: 0.3217 - accuracy: 0.8693 - val_loss: 0.3322 - val_accuracy: 0.8604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmOawFTAW_yD",
        "outputId": "72ca71dd-1b90-4759-8b35-c0589f70fe0e"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_dataset)\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 56s 143ms/step - loss: 0.3299 - accuracy: 0.8616\n",
            "Test Loss: 0.3298826515674591\n",
            "Test Accuracy: 0.8615999817848206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8oMPrwv21aV",
        "outputId": "e35e8dc7-603d-4b9f-f417-08f867aeb57f"
      },
      "source": [
        "# predict on a sample text without padding.\n",
        "\n",
        "sample_text = ('good is great')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n",
        "\n",
        "sample_text = ('bad equals very bad. Worse')\n",
        "predictions = model.predict(np.array([sample_text]))\n",
        "print(predictions)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.9038882]]\n",
            "[[-1.7162021]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPsBxOpcLBaB"
      },
      "source": [
        "x = tfds.as_numpy(test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOwGYT4ELyqm"
      },
      "source": [
        "for ele in train_dataset.as_numpy_iterator():\n",
        "  print (ele)\n",
        "  print (\"---------------------\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VE5clnKW23Tm",
        "outputId": "1819b1fe-1835-4712-8314-b66858fa8297"
      },
      "source": [
        "?plt.figure(figsize=(16, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plot_graphs(history, 'accuracy')\n",
        "plt.subplot(1, 2, 2)\n",
        "plot_graphs(history, 'loss')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrVlS1ar2-Zl",
        "outputId": "834ec163-e7dd-4d2e-bba6-6ff35b826408"
      },
      "source": [
        "m = tf.keras.metrics.Accuracy()\n",
        "m.update_state([[0], [2], [3], [4]], [[0], [2], [3], [4]])\n",
        "m.result().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0iPZD-ACr7C"
      },
      "source": [
        "import copy\n",
        "vicab2 = copy.deepcopy(vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yyLRtxUC4OC"
      },
      "source": [
        "vicab2.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gm8qUDt5DDPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950a837f-d819-4f4a-d46b-edb6ed2f7737"
      },
      "source": [
        "vicab2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['', '1', '10', '2', '20', '3', '4', '5', '70s', '80s', '[UNK]',\n",
              "       'a', 'able', 'about', 'above', 'absolutely', 'across', 'act',\n",
              "       'acting', 'action', 'actor', 'actors', 'actress', 'actual',\n",
              "       'actually', 'add', 'admit', 'after', 'again', 'against', 'age',\n",
              "       'ago', 'air', 'all', 'almost', 'alone', 'along', 'already', 'also',\n",
              "       'although', 'always', 'am', 'amazing', 'america', 'american',\n",
              "       'among', 'an', 'and', 'animation', 'annoying', 'another', 'any',\n",
              "       'anyone', 'anything', 'anyway', 'apart', 'apparently', 'appear',\n",
              "       'appears', 'are', 'arent', 'around', 'art', 'as', 'ask', 'at',\n",
              "       'atmosphere', 'attempt', 'attempts', 'attention', 'audience',\n",
              "       'average', 'avoid', 'away', 'awful', 'b', 'baby', 'back',\n",
              "       'background', 'bad', 'badly', 'based', 'basically', 'battle', 'be',\n",
              "       'beautiful', 'beauty', 'became', 'because', 'become', 'becomes',\n",
              "       'been', 'before', 'begin', 'beginning', 'begins', 'behind',\n",
              "       'being', 'believable', 'believe', 'best', 'better', 'between',\n",
              "       'beyond', 'big', 'bill', 'bit', 'black', 'blood', 'body', 'book',\n",
              "       'boring', 'both', 'boy', 'boys', 'br', 'brilliant', 'bring',\n",
              "       'brings', 'british', 'brother', 'brothers', 'brought', 'budget',\n",
              "       'bunch', 'business', 'but', 'buy', 'by', 'call', 'called', 'came',\n",
              "       'camera', 'can', 'cannot', 'cant', 'car', 'care', 'career', 'case',\n",
              "       'cast', 'casting', 'certain', 'certainly', 'chance', 'change',\n",
              "       'character', 'characters', 'cheap', 'check', 'cheesy', 'child',\n",
              "       'children', 'christmas', 'cinema', 'cinematography', 'city',\n",
              "       'class', 'classic', 'clear', 'clearly', 'close', 'come', 'comedy',\n",
              "       'comes', 'comic', 'coming', 'comment', 'comments', 'complete',\n",
              "       'completely', 'cool', 'could', 'couldnt', 'country', 'couple',\n",
              "       'course', 'crap', 'crazy', 'create', 'credits', 'creepy', 'crime',\n",
              "       'cut', 'dance', 'dark', 'daughter', 'david', 'day', 'days', 'de',\n",
              "       'dead', 'deal', 'death', 'decent', 'decided', 'deep', 'definitely',\n",
              "       'deserves', 'despite', 'development', 'dialog', 'dialogue', 'did',\n",
              "       'didnt', 'die', 'different', 'difficult', 'directed', 'directing',\n",
              "       'direction', 'director', 'directors', 'disappointed', 'disney',\n",
              "       'do', 'documentary', 'does', 'doesnt', 'dog', 'doing', 'done',\n",
              "       'dont', 'doubt', 'down', 'dr', 'drama', 'dramatic', 'dream', 'due',\n",
              "       'dull', 'dumb', 'during', 'dvd', 'each', 'earlier', 'early',\n",
              "       'earth', 'easily', 'easy', 'editing', 'effect', 'effects',\n",
              "       'effort', 'either', 'elements', 'else', 'emotional', 'end',\n",
              "       'ending', 'ends', 'english', 'enjoy', 'enjoyable', 'enjoyed',\n",
              "       'enough', 'entertaining', 'entertainment', 'entire', 'episode',\n",
              "       'episodes', 'especially', 'etc', 'even', 'events', 'eventually',\n",
              "       'ever', 'every', 'everyone', 'everything', 'evil', 'exactly',\n",
              "       'example', 'excellent', 'except', 'expect', 'expected',\n",
              "       'expecting', 'experience', 'extremely', 'eye', 'eyes', 'face',\n",
              "       'fact', 'fails', 'fairly', 'fall', 'falls', 'family', 'famous',\n",
              "       'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fast', 'father',\n",
              "       'favorite', 'feature', 'features', 'feel', 'feeling', 'feels',\n",
              "       'felt', 'female', 'few', 'fight', 'fighting', 'figure', 'film',\n",
              "       'filmbr', 'filmed', 'filmmakers', 'films', 'final', 'finally',\n",
              "       'find', 'finds', 'fine', 'fire', 'first', 'five', 'flick',\n",
              "       'follow', 'footage', 'for', 'forced', 'forget', 'form', 'forward',\n",
              "       'found', 'four', 'free', 'french', 'friend', 'friends', 'from',\n",
              "       'full', 'fun', 'funny', 'future', 'game', 'gave', 'general',\n",
              "       'genre', 'george', 'get', 'gets', 'getting', 'girl', 'girls',\n",
              "       'give', 'given', 'gives', 'giving', 'go', 'god', 'goes', 'going',\n",
              "       'gone', 'good', 'gore', 'got', 'great', 'greatest', 'group',\n",
              "       'guess', 'guy', 'guys', 'had', 'half', 'hand', 'hands', 'happen',\n",
              "       'happened', 'happens', 'happy', 'hard', 'hardly', 'has', 'hate',\n",
              "       'have', 'havent', 'having', 'he', 'head', 'hear', 'heard', 'heart',\n",
              "       'hell', 'help', 'her', 'here', 'hero', 'herself', 'hes', 'high',\n",
              "       'highly', 'hilarious', 'him', 'himself', 'his', 'history', 'hit',\n",
              "       'hollywood', 'home', 'hope', 'horrible', 'horror', 'hot', 'hour',\n",
              "       'hours', 'house', 'how', 'however', 'huge', 'human', 'humor',\n",
              "       'husband', 'i', 'id', 'idea', 'ideas', 'if', 'ill', 'im',\n",
              "       'imagine', 'imdb', 'important', 'in', 'including', 'incredibly',\n",
              "       'indeed', 'inside', 'instead', 'interest', 'interested',\n",
              "       'interesting', 'into', 'involved', 'is', 'isnt', 'it', 'itbr',\n",
              "       'its', 'itself', 'ive', 'jack', 'james', 'jane', 'japanese', 'job',\n",
              "       'joe', 'john', 'joke', 'jokes', 'just', 'keep', 'keeps', 'kept',\n",
              "       'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kind',\n",
              "       'king', 'knew', 'know', 'known', 'knows', 'la', 'lack', 'lady',\n",
              "       'lame', 'last', 'late', 'later', 'laugh', 'laughs', 'lead',\n",
              "       'leading', 'leads', 'learn', 'least', 'leave', 'leaves', 'lee',\n",
              "       'left', 'less', 'let', 'lets', 'level', 'life', 'light', 'like',\n",
              "       'liked', 'line', 'lines', 'little', 'live', 'lives', 'living',\n",
              "       'local', 'long', 'look', 'looked', 'looking', 'looks', 'lost',\n",
              "       'lot', 'lots', 'love', 'loved', 'low', 'made', 'main', 'major',\n",
              "       'make', 'makes', 'making', 'male', 'man', 'manages', 'many',\n",
              "       'mark', 'material', 'matter', 'may', 'maybe', 'me', 'mean',\n",
              "       'means', 'meant', 'meet', 'meets', 'memorable', 'men', 'mention',\n",
              "       'mess', 'message', 'michael', 'middle', 'might', 'mind', 'minute',\n",
              "       'minutes', 'miss', 'missing', 'modern', 'moment', 'moments',\n",
              "       'money', 'monster', 'more', 'most', 'mostly', 'mother', 'move',\n",
              "       'movie', 'moviebr', 'movies', 'moving', 'mr', 'much', 'murder',\n",
              "       'music', 'musical', 'must', 'my', 'myself', 'mystery', 'name',\n",
              "       'named', 'nature', 'near', 'nearly', 'need', 'needed', 'needs',\n",
              "       'never', 'new', 'next', 'nice', 'night', 'no', 'none', 'nor',\n",
              "       'not', 'note', 'nothing', 'novel', 'now', 'number', 'obvious',\n",
              "       'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old',\n",
              "       'older', 'on', 'once', 'one', 'ones', 'only', 'open', 'opening',\n",
              "       'opinion', 'or', 'order', 'original', 'oscar', 'other', 'others',\n",
              "       'otherwise', 'our', 'out', 'outside', 'over', 'overall', 'own',\n",
              "       'parents', 'part', 'particular', 'particularly', 'parts', 'past',\n",
              "       'paul', 'pay', 'people', 'perfect', 'perfectly', 'performance',\n",
              "       'performances', 'perhaps', 'period', 'person', 'personal', 'peter',\n",
              "       'picture', 'piece', 'place', 'play', 'played', 'playing', 'plays',\n",
              "       'please', 'plenty', 'plot', 'plus', 'point', 'points', 'police',\n",
              "       'political', 'poor', 'poorly', 'portrayed', 'possible', 'possibly',\n",
              "       'potential', 'power', 'powerful', 'predictable', 'premise',\n",
              "       'present', 'pretty', 'previous', 'probably', 'problem', 'problems',\n",
              "       'production', 'put', 'quality', 'question', 'quickly', 'quite',\n",
              "       'rather', 'rating', 'read', 'reading', 'real', 'realistic',\n",
              "       'reality', 'realize', 'really', 'reason', 'recommend', 'red',\n",
              "       'relationship', 'release', 'released', 'remake', 'remember',\n",
              "       'rent', 'rest', 'result', 'return', 'review', 'reviews', 'richard',\n",
              "       'ridiculous', 'right', 'robert', 'rock', 'role', 'roles',\n",
              "       'romance', 'romantic', 'room', 'run', 'running', 'sad', 'said',\n",
              "       'same', 'save', 'saw', 'say', 'saying', 'says', 'scary', 'scene',\n",
              "       'scenes', 'school', 'scifi', 'score', 'screen', 'screenplay',\n",
              "       'script', 'season', 'second', 'secret', 'see', 'seeing', 'seem',\n",
              "       'seemed', 'seems', 'seen', 'sense', 'sequel', 'sequence',\n",
              "       'sequences', 'series', 'serious', 'seriously', 'set', 'sets',\n",
              "       'setting', 'several', 'sex', 'sexual', 'shame', 'she', 'shes',\n",
              "       'short', 'shot', 'shots', 'should', 'show', 'showing', 'shown',\n",
              "       'shows', 'side', 'silly', 'similar', 'simple', 'simply', 'since',\n",
              "       'single', 'sister', 'sit', 'situation', 'slow', 'small', 'so',\n",
              "       'society', 'some', 'somehow', 'someone', 'something', 'sometimes',\n",
              "       'somewhat', 'son', 'song', 'songs', 'soon', 'sorry', 'sort',\n",
              "       'sound', 'sounds', 'soundtrack', 'space', 'special', 'stage',\n",
              "       'stand', 'star', 'stars', 'start', 'started', 'starts', 'stay',\n",
              "       'still', 'stop', 'stories', 'story', 'storyline', 'straight',\n",
              "       'strange', 'street', 'strong', 'stuff', 'stupid', 'style',\n",
              "       'subject', 'such', 'superb', 'supporting', 'supposed', 'sure',\n",
              "       'surprise', 'surprised', 'suspense', 'take', 'taken', 'takes',\n",
              "       'taking', 'tale', 'talent', 'talk', 'talking', 'team',\n",
              "       'television', 'tell', 'tells', 'ten', 'terrible', 'than', 'that',\n",
              "       'thats', 'the', 'theater', 'their', 'them', 'theme', 'themselves',\n",
              "       'then', 'there', 'theres', 'these', 'they', 'theyre', 'thing',\n",
              "       'things', 'think', 'thinking', 'third', 'this', 'those', 'though',\n",
              "       'thought', 'three', 'thriller', 'through', 'throughout', 'time',\n",
              "       'times', 'title', 'to', 'today', 'together', 'told', 'tom', 'too',\n",
              "       'took', 'top', 'total', 'totally', 'towards', 'town', 'tried',\n",
              "       'tries', 'true', 'truly', 'truth', 'try', 'trying', 'turn',\n",
              "       'turned', 'turns', 'tv', 'twist', 'two', 'type', 'typical',\n",
              "       'under', 'understand', 'unfortunately', 'unique', 'unless',\n",
              "       'unlike', 'until', 'up', 'upon', 'us', 'use', 'used', 'using',\n",
              "       'usual', 'usually', 'various', 'version', 'very', 'video', 'view',\n",
              "       'viewer', 'viewers', 'viewing', 'violence', 'voice', 'wait',\n",
              "       'want', 'wanted', 'wants', 'war', 'was', 'wasnt', 'waste', 'watch',\n",
              "       'watched', 'watching', 'way', 'ways', 'we', 'weak', 'weird',\n",
              "       'well', 'went', 'were', 'what', 'whatever', 'whats', 'when',\n",
              "       'where', 'whether', 'which', 'while', 'white', 'who', 'whole',\n",
              "       'whom', 'whos', 'whose', 'why', 'wife', 'will', 'wish', 'with',\n",
              "       'within', 'without', 'woman', 'women', 'wonder', 'wonderful',\n",
              "       'wont', 'word', 'words', 'work', 'worked', 'working', 'works',\n",
              "       'world', 'worse', 'worst', 'worth', 'would', 'wouldnt', 'write',\n",
              "       'writer', 'writers', 'writing', 'written', 'wrong', 'year',\n",
              "       'years', 'yes', 'yet', 'york', 'you', 'youll', 'young', 'your',\n",
              "       'youre', 'yourself', 'youve', 'zombie', '\\x96'], dtype='<U14')"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA_QK-mONBvp",
        "outputId": "1f231d98-49b1-42ec-8b45-bdca887e19ff"
      },
      "source": [
        "\n",
        "lst = []\n",
        "def func(text, label):\n",
        "  lst.append([text, label])\n",
        "  return text, label\n",
        "\n",
        "\n",
        "test_dataset.map(func)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<MapDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMT_eNgiNCdZ",
        "outputId": "27b8f7b4-efde-4b56-f261-763e9e90efcb"
      },
      "source": [
        "lst"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[<tf.Tensor 'args_0:0' shape=(None,) dtype=string>,\n",
              "  <tf.Tensor 'args_1:0' shape=(None,) dtype=int64>]]"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sK5A3oAMNnQy"
      },
      "source": [
        "for ele in test_dataset.as_numpy_iterator():\n",
        "  print (ele)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvWb_pylONE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174da80d-d7fb-44c3-83cc-3651c1fe1795"
      },
      "source": [
        "tf.keras.models.save_model(model=model, filepath=\"/content/drive/MyDrive/sentiment/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_4_layer_call_fn, lstm_cell_4_layer_call_and_return_conditional_losses, lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses, lstm_cell_4_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/sentiment/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/sentiment/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDe9UYTuKFCG",
        "outputId": "0cff6168-b28d-4ae3-fe06-56c6580d90f4"
      },
      "source": [
        "tf.saved_model.save(obj=model, export_dir=\"/content/drive/MyDrive/sentiment\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/sentiment/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/sentiment/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdA5dwObtlgG",
        "outputId": "23feca35-d357-47ac-f06c-cb4b4084ac3c"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/sentiment/model\", save_format=\"tf\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_20_layer_call_fn, lstm_cell_20_layer_call_and_return_conditional_losses, lstm_cell_19_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/sentiment/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/sentiment/model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk9kWUJ0uQfU"
      },
      "source": [
        "for layer in model.layers: print(layer.get_config(), layer.get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYHBnq3UxQ3J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvx-PPQSwq7T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad1UEHR_wq98",
        "outputId": "7b1850dd-cf11-4b60-896e-6e203fdf09c5"
      },
      "source": [
        "input_array = np.random.randint(len(encoder.get_vocabulary()), size=(3, 1))\n",
        "\n",
        "model_temp = tf.keras.Sequential()\n",
        "model_temp.add(encoder)\n",
        "model_temp.add(tf.keras.layers.Embedding( \n",
        "    input_dim=len(encoder.get_vocabulary()),\n",
        "    output_dim=64,\n",
        "    # Use masking to handle the variable sequence lengths\n",
        "    mask_zero=True))\n",
        "model_temp.compile('rmsprop', 'mse')\n",
        "# output_array = model_temp.predict(\"hello world this is great!\")\n",
        "# print(output_array.shape)\n",
        "\n",
        "\n",
        "sample_text = ('The movie was cool. The animation and the graphics '\n",
        "               'were out of this world. I would recommend this movie.')\n",
        "predictions = model_temp.predict(np.array([sample_text]))\n",
        "print(len(predictions))\n",
        "print(len(predictions[0]))\n",
        "print(len(predictions[0][0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# The model will take as input an integer matrix of size (batch,\n",
        "# input_length), and the largest integer (i.e. word index) in the input\n",
        "# should be no larger than 999 (vocabulary size).\n",
        "# Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
        "# dimension.\n",
        "# input_array = np.random.randint(900, size=(3, 10))\n",
        "# model_temp.compile('rmsprop', 'mse')\n",
        "# output_array = model_temp.predict(input_array)\n",
        "# print(output_array.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "19\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3MYJNaTw6Uc",
        "outputId": "ac7bbc64-44b4-438e-aad7-0296cb16987c"
      },
      "source": [
        "print (output_array[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.0051492  -0.01514421  0.0233087  -0.03882884  0.01593846]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xalLvh4LxYy-",
        "outputId": "3b1f4d6d-422b-436f-bec8-f09bf60c2085"
      },
      "source": [
        "input_array[0][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "696"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAdc10-MyISv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}