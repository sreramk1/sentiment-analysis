{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_sentiment_from_existing_weights_p2v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhM3EalLC+ahLD8E/Qtdly",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreramk1/sentiment-analysis/blob/main/training_notebooks/train_sentiment_from_existing_weights_p2v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKYTPCqyK6-E",
        "outputId": "9ff65a38-8e78-487d-f157-3bfa617803cd"
      },
      "source": [
        "!rm -r sentiment-analysis\n",
        "!git clone https://github.com/sreramk1/sentiment-analysis.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentiment-analysis'...\n",
            "remote: Enumerating objects: 217, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (149/149), done.\u001b[K\n",
            "remote: Total 217 (delta 118), reused 142 (delta 59), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (217/217), 8.84 MiB | 11.47 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0wCzhHBLWNd"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/sentiment-analysis')\n",
        "os.environ['PYTHONPATH'] += \":/content/sentiment-analysis\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ux7hF2yjLba0"
      },
      "source": [
        "from util.jupyter_helpers import display_tf_ds\n",
        "\n",
        "from train_validate_predict.pandas_read_ds_from_csv import PandasReadDatasetFromCSV\n",
        "from sentiment_v1.preprocess_ds import TweetReviewCsvToPdDataFrame\n",
        "from sentiment_v1.convert_ds_to_tensors import TweetReviewTfDataset\n",
        "from sentiment_v1.model_builder import SentimentLSTMDense64Dense32Dense16Dense8Dense1\n",
        "from train_validate_predict.model_predict import ModelPredict\n",
        "from train_validate_predict.model_train_validate_predict import ModelTrainValidatePredict\n",
        "from model.keras_sequence_model_weights import KerasSequenceModelWeights"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7roXxPsQPyeh"
      },
      "source": [
        "def model_build_and_train(weights=None, \n",
        "                          path=\"/content/sentiment-analysis/third_party/dataset/airline_sentiment_analysis.csv\", \n",
        "                          negative_reivew=\"This is a bad airline\",\n",
        "                          positive_review=\"This is a good airline\"):\n",
        "  pd_dataset = PandasReadDatasetFromCSV(path)\n",
        "  pd_dataset.load_dataset()\n",
        "\n",
        "  tweet_review_csv_to_pd_dataframe = TweetReviewCsvToPdDataFrame(pd_dataset)\n",
        "  tweet_review_tf_ds = TweetReviewTfDataset(tweet_review_csv_to_pd_dataframe)\n",
        "\n",
        "  model_builder = SentimentLSTMDense64Dense32Dense16Dense8Dense1(tf_ds_store=tweet_review_tf_ds, \n",
        "                                                                 layered_weights=weights)\n",
        "  model_builder.build_model()\n",
        "  model = model_builder.get_model()\n",
        "\n",
        "  model_trainer = ModelTrainValidatePredict(tweet_review_tf_ds, model)\n",
        "  print(\"negative review before training:\" + str(model_trainer.predict(negative_reivew)))\n",
        "  print(\"positive review before training:\" + str(model_trainer.predict(positive_review)))\n",
        "\n",
        "  model_trainer.train()\n",
        "  model_trainer.evaluate()\n",
        "  \n",
        "  print(\"negative review after training:\" + str(model_trainer.predict(negative_reivew)))\n",
        "  print(\"positive review after training:\" + str(model_trainer.predict(positive_review)))\n",
        "\n",
        "  return model_trainer, model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63kDwTxPLd-Z",
        "outputId": "4e44fb4a-f3d8-4441-d628-0a1c819c18f4"
      },
      "source": [
        "sequence_model_weights = KerasSequenceModelWeights()\n",
        "loaded_weights = sequence_model_weights.load_weights_from_file(\"/content/sentiment-analysis/trained_weights/weights.json\")\n",
        "\n",
        "model_builder = SentimentLSTMDense64Dense32Dense16Dense8Dense1(layered_weights=loaded_weights)\n",
        "model_builder.build_model()\n",
        "model = model_builder.get_model()\n",
        "\n",
        "model_predict = ModelPredict(model)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UUs9gFTLwsM",
        "outputId": "1e34528f-2b69-4605-8fdd-a35707e3acce"
      },
      "source": [
        "model_predict.predict(\"This is a great airline\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.2447302]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHzyN2ThNPY5",
        "outputId": "919bd194-7df3-4072-9d1d-ec515aa6f768"
      },
      "source": [
        "model_predict.predict(\"This is a useless airline\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.317034]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yc-07Re-Om2t",
        "outputId": "651b891a-f167-45dd-c1aa-60e7bf969456"
      },
      "source": [
        "model_trainer, model_trained = model_build_and_train(sequence_model_weights.get_weights())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative review before training:[[-1.4881439]]\n",
            "positive review before training:[[2.0682502]]\n",
            "Epoch 1/10\n",
            "144/145 [============================>.] - ETA: 0s - loss: 0.0879 - accuracy: 0.9760WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
            "145/145 [==============================] - 20s 88ms/step - loss: 0.0881 - accuracy: 0.9760 - val_loss: 0.1015 - val_accuracy: 0.9706\n",
            "Epoch 2/10\n",
            "145/145 [==============================] - 9s 65ms/step - loss: 0.0719 - accuracy: 0.9796\n",
            "Epoch 3/10\n",
            "145/145 [==============================] - 10s 66ms/step - loss: 0.0612 - accuracy: 0.9829\n",
            "Epoch 4/10\n",
            "145/145 [==============================] - 10s 66ms/step - loss: 0.0532 - accuracy: 0.9854\n",
            "Epoch 5/10\n",
            "145/145 [==============================] - 10s 66ms/step - loss: 0.0448 - accuracy: 0.9879\n",
            "Epoch 6/10\n",
            "145/145 [==============================] - 9s 65ms/step - loss: 0.0385 - accuracy: 0.9891\n",
            "Epoch 7/10\n",
            "145/145 [==============================] - 9s 65ms/step - loss: 0.0306 - accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "145/145 [==============================] - 10s 66ms/step - loss: 0.0260 - accuracy: 0.9939\n",
            "Epoch 9/10\n",
            "145/145 [==============================] - 9s 65ms/step - loss: 0.0220 - accuracy: 0.9950\n",
            "Epoch 10/10\n",
            "145/145 [==============================] - 9s 65ms/step - loss: 0.0184 - accuracy: 0.9956\n",
            "3/3 [==============================] - 0s 131ms/step - loss: 0.1755 - accuracy: 0.9545\n",
            "negative review after training:[[-2.1612248]]\n",
            "positive review after training:[[3.4747014]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWsazN7mRmat"
      },
      "source": [
        "sequence_model_weights.set_model(model_trained)\n",
        "sequence_model_weights.read_weights_from_model()\n",
        "sequence_model_weights.write_weights_to_file(\"weights.json\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-ACGAyDStKI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}