{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_sentiment_p1v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN/g9X7ez0Z6H6j3FPxJKWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreramk1/sentiment-analysis/blob/main/training_notebooks/train_sentiment_p1v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esIcWboKCBvL"
      },
      "source": [
        "# Training the Model for the first time (initialized with random weights)\n",
        "\n",
        "In this notebook, I had used the classes I had written to simplify the training process for the sentiment analysis model: https://github.com/sreramk1/sentiment-analysis.git"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLJiw0RCwU8s",
        "outputId": "99c9da5d-21bb-4ae4-cc36-cf259b50c35b"
      },
      "source": [
        "!rm -r sentiment-analysis\n",
        "!git clone https://github.com/sreramk1/sentiment-analysis.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentiment-analysis'...\n",
            "remote: Enumerating objects: 225, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (156/156), done.\u001b[K\n",
            "remote: Total 225 (delta 120), reused 146 (delta 60), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (225/225), 15.18 MiB | 4.59 MiB/s, done.\n",
            "Resolving deltas: 100% (120/120), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa-oZ4x738pF"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "sys.path.append('/content/sentiment-analysis')\n",
        "os.environ['PYTHONPATH'] += \":/content/sentiment-analysis\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zyVTSMfzlEz"
      },
      "source": [
        "from util.jupyter_helpers import display_tf_ds\n",
        "\n",
        "from train_validate_predict.pandas_read_ds_from_csv import PandasReadDatasetFromCSV\n",
        "from sentiment_v1.preprocess_ds import TweetReviewCsvToPdDataFrame\n",
        "from sentiment_v1.convert_ds_to_tensors import TweetReviewTfDataset\n",
        "from sentiment_v1.model_builder import SentimentLSTMDense64Dense32Dense16Dense8Dense1\n",
        "from train_validate_predict.model_train_validate_predict import ModelTrainValidatePredict\n",
        "from model.keras_sequence_model_weights import KerasSequenceModelWeights"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imUkUVHA1fOl"
      },
      "source": [
        "pd_dataset = PandasReadDatasetFromCSV(\"/content/sentiment-analysis/third_party/dataset/airline_sentiment_analysis.csv\")\n",
        "pd_dataset.load_dataset()\n",
        "tweet_review_csv_to_pd_dataframe = TweetReviewCsvToPdDataFrame(pd_dataset)\n",
        "tweet_review_tf_ds = TweetReviewTfDataset(tweet_review_csv_to_pd_dataframe)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iqbuw78t8aiu",
        "outputId": "170131ea-5938-45f7-a6fe-b655f81cb4a3"
      },
      "source": [
        "model_builder = SentimentLSTMDense64Dense32Dense16Dense8Dense1(tf_ds_store=tweet_review_tf_ds)\n",
        "model_builder.build_model()\n",
        "model = model_builder.get_model()\n",
        "model_trainer = ModelTrainValidatePredict(tweet_review_tf_ds, model)\n",
        "model_trainer.predict(\"This is a bad airline\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00026961]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1N9Mdhb8ztk",
        "outputId": "319bd091-47dc-49fd-81e6-66161d3ff3fa"
      },
      "source": [
        "model_trainer.train()\n",
        "model_trainer.evaluate()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "145/145 [==============================] - ETA: 0s - loss: 0.6023 - accuracy: 0.7953WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n",
            "145/145 [==============================] - 20s 90ms/step - loss: 0.6023 - accuracy: 0.7953 - val_loss: 0.4349 - val_accuracy: 0.7951\n",
            "Epoch 2/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.4013 - accuracy: 0.7953\n",
            "Epoch 3/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.2834 - accuracy: 0.8458\n",
            "Epoch 4/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.1769 - accuracy: 0.9389\n",
            "Epoch 5/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.1289 - accuracy: 0.9572\n",
            "Epoch 6/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.0987 - accuracy: 0.9687\n",
            "Epoch 7/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.0767 - accuracy: 0.9766\n",
            "Epoch 8/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.0605 - accuracy: 0.9820\n",
            "Epoch 9/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.0471 - accuracy: 0.9866\n",
            "Epoch 10/10\n",
            "145/145 [==============================] - 10s 67ms/step - loss: 0.0376 - accuracy: 0.9890\n",
            "3/3 [==============================] - 0s 117ms/step - loss: 0.3175 - accuracy: 0.9129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.31747668981552124, 0.9129493236541748)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N830dxYJ9nOD",
        "outputId": "d0468bc9-0505-42d4-e002-6039f55fcc38"
      },
      "source": [
        "print(\"after training, bad review:\" + str(model_trainer.predict(\"This is a bad airline\")))\n",
        "print(\"after training, good review:\" + str(model_trainer.predict(\"This is a good airline\")))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after training, bad review:[[-1.3539096]]\n",
            "after training, good review:[[2.8381493]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNrYu6oPUYe_"
      },
      "source": [
        "# Create a new model, load the trained weights from the file into it, and predict "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKJPJRRLAyOS"
      },
      "source": [
        "sequence_model_weights = KerasSequenceModelWeights()\n",
        "sequence_model_weights.set_model(model)\n",
        "sequence_model_weights.read_weights_from_model()\n",
        "sequence_model_weights.write_weights_to_file(\"weights.json\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHhz3xtnB9fM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14b85e2d-4ab5-4e7d-ab6c-e4776b265aca"
      },
      "source": [
        "another_sequence_model_weights = KerasSequenceModelWeights()\n",
        "loaded_weights = another_sequence_model_weights.load_weights_from_file(\"weights.json\")\n",
        "\n",
        "second_model_builder = SentimentLSTMDense64Dense32Dense16Dense8Dense1(layered_weights=loaded_weights)\n",
        "second_model_builder.build_model()\n",
        "second_model = second_model_builder.get_model()\n",
        "second_model_tvp = ModelTrainValidatePredict(tweet_review_tf_ds, second_model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzGZpm3_EgpR",
        "outputId": "0d9716b6-eaf0-4647-c79e-0de85d199557"
      },
      "source": [
        "another_sequence_model_weights.set_model(second_model)\n",
        "another_sequence_model_weights.set_weights_to_model()\n",
        "\n",
        "print(\"------------------------------------------------------------\")\n",
        "print(\"for a bad review\" + str(second_model_tvp.predict(\"This is a bad airline\")))\n",
        "print(\"for a good review\" + str(second_model_tvp.predict(\"This is a good airline\")))\n",
        "print(\"------------------------------------------------------------\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------\n",
            "for a bad review[[-1.3539096]]\n",
            "for a good review[[2.8381493]]\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyAtjBcfVkIE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}